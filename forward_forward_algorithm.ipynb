{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "199b1a1d-6b1a-4272-93b5-8245838242a0",
   "metadata": {},
   "source": [
    "# The Forward-Forward Algorithm: Some Preliminary Investigations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6abda0-25d6-497a-bf70-b2219c042c28",
   "metadata": {},
   "source": [
    "> **The aim of this repository is to implement The Forward-Forward Training Algorithm (FFX) using PyTorch**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb85a51-2a33-4076-bcb8-0850de7dff8a",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "The aim of this paper is to introduce a new learning procedure for neural networks and to demonstrate that it works well enough on a few small problems to be worth\n",
    "serious investigation. The Forward-Forward algorithm replaces the forward and backward passes of backpropagation by two forward passes, one with positive\n",
    "(i.e. real) data and the other with negative data which could be generated by the network itself. Each layer has its own objective function which is simply to have\n",
    "high goodness for positive data and low goodness for negative data. The sum of the squared activities in a layer can be used as the goodness but there are many other\n",
    "possibilities, including minus the sum of the squared activities. If the positive and negative passes can be separated in time, the negative passes can be done offline,\n",
    "which makes the learning much simpler in the positive pass and allows video to be pipelined through the network without ever storing activities or stopping to\n",
    "propagate derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe263c30-decf-4511-a648-9b9301c7476b",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9c680c-6463-497c-81bb-d86d1f557957",
   "metadata": {},
   "source": [
    "### Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0f7c16-f0f7-4216-823f-550c7c21d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1311e0f0-172f-4bb4-8003-373e9cff787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tools/anaconda3/envs/main/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1769fe-f731-407e-8207-04fa3dc20cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a5ff44-ca93-479e-b4e4-d57007cdf899",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3270b1a0-2e07-49e7-928f-37e622cea3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_Loader:\n",
    "    \n",
    "    def __init__(self, batch_size_train=50000, batch_size_test=10000, batch_size_eval=10000, path='./data/', ):\n",
    "        \n",
    "        self.batch_size_train = batch_size_train\n",
    "        self.batch_size_test = batch_size_test\n",
    "        \n",
    "        self.path = path\n",
    "        \n",
    "        self.dl_train = None\n",
    "        self.dl_test = None\n",
    "        self.dl_eval = None\n",
    "        \n",
    "        self.transform = transform = Compose([\n",
    "            ToTensor(),\n",
    "            Normalize((0.1307,), (0.3081,)),\n",
    "            Lambda(lambda x: torch.flatten(x))])\n",
    "        \n",
    "    def data_load(self, download=True, shuffle=True):\n",
    "        \n",
    "        self.dl_train, self.dl_test, self.dl_eval = self.data_loader(dpath=self.path, download=download, shuffle=shuffle)\n",
    "        \n",
    "    def data_loader(self, download=True, shuffle=True, dpath='./data/'):\n",
    "      \n",
    "        dl_train = DataLoader(\n",
    "            MNIST(dpath, train=True,\n",
    "                  download=download,\n",
    "                  transform=self.transform),\n",
    "            batch_size=self.batch_size_train, shuffle=shuffle)\n",
    "\n",
    "        dl_test = DataLoader(\n",
    "            MNIST(dpath, train=False,\n",
    "                  download=download,\n",
    "                  transform=self.transform),\n",
    "            batch_size=self.batch_size_test, shuffle=shuffle)\n",
    "\n",
    "        dl_eval = DataLoader(\n",
    "            MNIST(dpath, train=False,\n",
    "                  download=download,\n",
    "                  transform=self.transform),\n",
    "            batch_size=self.batch_size_test, shuffle=False)\n",
    "        return dl_train, dl_test, dl_eval\n",
    "    \n",
    "    def overlay(self, images, labels):\n",
    "        # Replace the first 10 pixels of images with one-hot-encoded labels\n",
    "        size = images.shape[0]\n",
    "        data = images.clone()\n",
    "        data[:, :10] *= 0.0\n",
    "        data[range(0, size), labels] = images.max()\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def data_positive(self, images, labels):\n",
    "        return self.overlay(images, labels)\n",
    "    \n",
    "    def data_negative(self, images, labels):\n",
    "        neg_labels = labels.clone()\n",
    "        for inx, lbl in enumerate(labels):\n",
    "            _labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "            _labels.pop(lbl.item()) # remove y from labels to generate negative data\n",
    "            neg_labels[inx] = torch.tensor(np.random.choice(_labels)).cuda()\n",
    "        return self.overlay(images, neg_labels)\n",
    "    \n",
    "    def visualize(data, name='', idx=0):\n",
    "        img = data[idx].cpu().reshape(28, 28)\n",
    "        plt.figure(figsize = (4, 4))\n",
    "        plt.title(name)\n",
    "        plt.imshow(reshaped, cmap=\"gray\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ee83fe-be78-46a0-9e45-ca0fabc3fab2",
   "metadata": {},
   "source": [
    "### FFX Layer Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c6bf827-bb3d-43a5-9fcb-c60c88f3ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFLayer(nn.Linear):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 in_features, \n",
    "                 out_features,\n",
    "                 bias=True, \n",
    "                 device=None, \n",
    "                 dtype=None):\n",
    "        \n",
    "        super().__init__(in_features, out_features, bias, device, dtype)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigm = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.lrelu = nn.LeakyReLU()\n",
    "        self.rrelu = nn.RReLU()\n",
    "        self.gelu = nn.GELU()\n",
    "        self.opt = AdamW(self.parameters(), lr=0.02)\n",
    "        self.threshold = 2.0\n",
    "        \n",
    "        if not device:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "    def forward(self, x):\n",
    "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
    "        return self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0)).to(self.device)\n",
    "\n",
    "    def train(self, xpos, xneg):\n",
    "        g_pos = self.forward(xpos).pow(2).mean(1)\n",
    "        g_neg = self.forward(xneg).pow(2).mean(1)\n",
    "        # The following loss pushes pos (neg) samples to values larger (smaller) than the self.threshold.\n",
    "        loss = torch.log(1 + torch.exp(torch.cat([-g_pos + self.threshold, g_neg - self.threshold]))).mean()\n",
    "        self.opt.zero_grad()\n",
    "        # this backward just compute the derivative and hence is not considered backpropagation.\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        return self.forward(xpos).detach(), self.forward(xneg).detach(), loss.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b53481-dc32-4b21-9fad-dd34d991fa96",
   "metadata": {},
   "source": [
    "### Forward Forward Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "78a67564-1d14-4e41-8d08-c8805929892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFX(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, DataLoader, dims, epochs=50, device=None):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.layers = []\n",
    "        self.DL = DataLoader\n",
    "        if not device:\n",
    "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        else:\n",
    "            self.device = device\n",
    "            print(\"DEVIVE\")\n",
    "        for d in range(len(dims) - 1):\n",
    "            self.layers += [FFLayer(dims[d], dims[d + 1], device=device)]\n",
    "\n",
    "    \"\"\"\n",
    "    There are two approaches for batch training:\n",
    "    1. Iterate batches for all layers. ---> easy\n",
    "    2. Iterate batches for each layer. ---> need to create new batches for next layer input\n",
    "    We use 1 for the following two training methods.\n",
    "    \"\"\"\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        Train method 1: train all layers for each epoch for each batch.\n",
    "        \"\"\"\n",
    "        data_loader = self.DL.dl_train\n",
    "        print(DL)\n",
    "        for batch_i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "            print(\"Training Batch (Size:\", str(x_batch.size(dim=0)) + ')', '#', batch_i + 1, '/', len(data_loader))\n",
    "            batch_pos, batch_neg = self.DL.data_positive(x_batch, y_batch), self.DL.data_negative(x_batch, y_batch)\n",
    "            batch_pos, batch_neg = batch_pos.to(self.device), batch_neg.to(self.device)\n",
    "            for epoch in tqdm(range(self.epochs)):\n",
    "                h_batch_pos, h_batch_neg = batch_pos, batch_neg\n",
    "                for layer_i, layer in enumerate(self.layers):\n",
    "                    h_batch_pos, h_batch_neg, loss = layer.train(h_batch_pos, h_batch_neg)\n",
    "\n",
    "#     def train_2(self, data_loader):\n",
    "#         \"\"\"\n",
    "#         Train method 2: train all epochs for each layer for each batch.\n",
    "#         \"\"\"\n",
    "#         for batch_i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "#             batch_loss = 0\n",
    "#             print(\"Training Batch (Size:\", str(x_batch.size(dim=0)) + ')', '#', batch_i + 1, '/', len(data_loader))\n",
    "#             h_batch_pos, h_batch_neg = data_positive(x_batch, y_batch), data_negative(x_batch, y_batch)\n",
    "#             h_batch_pos, h_batch_neg = h_batch_pos.to(self.device), h_batch_neg.to(self.device)\n",
    "#             for layer_i, layer in enumerate(tqdm(self.layers)):\n",
    "#                 for epoch in range(self.epochs):\n",
    "#                     h_batch_pos_epoch, h_batch_neg_epoch, loss = layer.train(h_batch_pos, h_batch_neg)\n",
    "#                     batch_loss += loss.item()\n",
    "#                 h_batch_pos, h_batch_neg = h_batch_pos_epoch, h_batch_neg_epoch\n",
    "#             print('batch {} loss: {}'.format(batch_i + 1, batch_loss))\n",
    "\n",
    "#     def train_3(self, data_loader):\n",
    "#         \"\"\"\n",
    "#         Train method 3: train all layers for each batch for each epoch. [Slow but better?]\n",
    "#         \"\"\"\n",
    "#         cached_data = []\n",
    "#         for epoch in tqdm(range(self.epochs)):\n",
    "#             epoch_loss = 0\n",
    "#             for batch_i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "#                 # print(\"Training Batch (Size:\", str(x_batch.size(dim=0)) + ')', '#', batch_i + 1, '/', len(data_loader))\n",
    "#                 if (epoch + 1) == 1:\n",
    "#                     h_batch_pos, h_batch_neg = data_positive(x_batch, y_batch), data_negative(x_batch, y_batch)\n",
    "#                     h_batch_pos, h_batch_neg = h_batch_pos.to(self.device), h_batch_neg.to(self.device)\n",
    "#                     cached_data.append((h_batch_pos, h_batch_neg))\n",
    "#                 else:\n",
    "#                     h_batch_pos, h_batch_neg = cached_data[batch_i]\n",
    "#                 for layer_i, layer in enumerate(self.layers):\n",
    "#                     h_batch_pos_epoch, h_batch_neg_epoch, loss = layer.train(h_batch_pos, h_batch_neg)\n",
    "#                     epoch_loss += loss.item()\n",
    "#                     h_batch_pos, h_batch_neg = h_batch_pos_epoch, h_batch_neg_epoch\n",
    "#             print('   epoch {} loss: {}'.format(epoch + 1, epoch_loss))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, ds='test', dl=None):\n",
    "        \n",
    "        if ds=='test':\n",
    "            data_loader = self.DL.dl_test\n",
    "        elif ds=='eval':\n",
    "            data_loader = self.DL.dl_eval\n",
    "        elif ds=='train':\n",
    "            data_loader = self.DL.dl_train\n",
    "        else:\n",
    "            data_loader = dl\n",
    "        \n",
    "        all_predictions = torch.Tensor([])\n",
    "        all_labels = torch.Tensor([])\n",
    "        all_predictions, all_labels = all_predictions.to(self.device), all_labels.to(self.device)\n",
    "        for batch_i, (x_batch, y_batch) in enumerate(data_loader):\n",
    "            print(\"Evaluation Batch (Size:\", str(x_batch.size(dim=0)) + ')', '#', batch_i + 1, '/', len(data_loader))\n",
    "            x_batch, y_batch = x_batch.to(self.device), y_batch.to(self.device)\n",
    "            goodness_per_label_batch = []\n",
    "            for label in range(10):\n",
    "                h_batch = self.DL.overlay(x_batch, label)\n",
    "                goodness_batch = []\n",
    "                for layer in self.layers:\n",
    "                    h_batch = layer(h_batch)\n",
    "                    goodness_batch += [h_batch.pow(2).mean(1)]\n",
    "                goodness_per_label_batch += [sum(goodness_batch).unsqueeze(1)]\n",
    "            goodness_per_label_batch = torch.cat(goodness_per_label_batch, 1)\n",
    "            predictions_batch = goodness_per_label_batch.argmax(1)\n",
    "            all_predictions = torch.cat((all_predictions, predictions_batch), 0)\n",
    "            all_labels = torch.cat((all_labels, y_batch), 0)\n",
    "        return all_predictions.eq(all_labels).float().mean().item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09aba04-b2d0-4d2c-af2c-232bf19fa12f",
   "metadata": {},
   "source": [
    "### Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "15a8e7dc-d988-44c1-a413-f1d0a1614c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "364802ee-49b1-4228-a4a1-83916435bd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f648d189070>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2b19b6e7-ede8-4cca-9884-03a386b9c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DL = MNIST_Loader()\n",
    "DL.data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61b36573-99a0-4c6f-8f16-833e5227afc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVIVE\n"
     ]
    }
   ],
   "source": [
    "model = FFX(DataLoader=DL, dims=[784, 2000, 2000, 2000, 2000], device='cpu', epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "abbff46c-133b-4570-b008-4e97097f25e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MNIST_Loader object at 0x7f63ff3dcfd0>\n",
      "Training Batch (Size: 50000) # 1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:50<00:00, 22.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Batch (Size: 10000) # 2 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:22<00:00,  4.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_tic = time.time()\n",
    "model.train()\n",
    "train_toc = time.time()\n",
    "train_duration = round(train_toc - train_tic, 2)\n",
    "print(train_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a08616d-b513-4c23-893d-e5439dc05f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 145.04s\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training time: {train_duration}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9aa7d61-a60b-40d3-8e22-dfaa1daabfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Batch (Size: 50000) # 1 / 2\n",
      "Evaluation Batch (Size: 10000) # 2 / 2\n",
      "train error: 85.78%\n"
     ]
    }
   ],
   "source": [
    "print('train error:', str(round((1.0 - model.predict(ds='train')) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5b53197c-d219-4538-baa0-5cf2d54c0637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Batch (Size: 10000) # 1 / 1\n",
      "test error: 85.39%\n"
     ]
    }
   ],
   "source": [
    "print('test error:', str(round((1.0 - model.predict(ds='test')) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7af4305f-3147-439b-96c9-e70278a4c2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Batch (Size: 10000) # 1 / 1\n",
      "eval error: 85.39%\n"
     ]
    }
   ],
   "source": [
    "print('eval error:', str(round((1.0 - model.predict(ds='eval')) * 100, 2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5a48dd-aaec-475d-a70b-1dd4e3fd81cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
